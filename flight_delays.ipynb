{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07a856df-f970-4266-840f-6b169872d6ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from pyspark.sql.functions import col, avg, max, count, when, sum, round\n",
    "\n",
    "# Load the data\n",
    "df_base = spark.read.csv(\"/databricks-datasets/flights/departuredelays.csv\", \n",
    "                          header=True, inferSchema=True)\n",
    "\n",
    "df_large = df_base\n",
    "for i in range(9):\n",
    "    df_large = df_large.union(df_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1be9ce2b-5a51-4fd2-bd75-a2231484f19c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Data Processing Pipeline\n",
    "# Apply transformations\n",
    "\n",
    "# Filter the data\n",
    "# 1. Filter flights with delay > 60 minutes\n",
    "df_filtered1 = df_large.filter(col(\"delay\") > 60)\n",
    "\n",
    "# Filter flights originating from New York airports\n",
    "df_filtered2 = df_filtered1.filter(col(\"origin\").isin([\"JFK\", \"LGA\", \"EWR\"]))\n",
    "\n",
    "# Column transformation using withColumn\n",
    "# Add a delay category column\n",
    "df_transformed = df_filtered2.withColumn(\n",
    "    \"delay_category\",\n",
    "    when(col(\"delay\") > 180, \"Very High\")\n",
    "    .when(col(\"delay\") > 120, \"High\")\n",
    "    .otherwise(\"Moderate\")\n",
    ")\n",
    "\n",
    "# groupBy with aggregation\n",
    "df_agg = df_transformed.groupBy(\"origin\", \"destination\") \\\n",
    "                       .agg(\n",
    "                           avg(\"delay\").alias(\"avg_delay\"),\n",
    "                           max(\"delay\").alias(\"max_delay\"),\n",
    "                           count(\"*\").alias(\"num_flights\")\n",
    "                       ) \\\n",
    "                       .filter(col(\"num_flights\") > 50)  \n",
    "\n",
    "# Complex Aggregation\n",
    "## Goal: For each origin-destination pair:\n",
    "### 1. Average delay\n",
    "### 2. Maximum delay\n",
    "### 3. Count of flights\n",
    "### 4. Count of \"Very High\" delay flights\n",
    "### 5. Percentage of flights with delay > 120 minutes\n",
    "\n",
    "df_agg = df_transformed.groupBy(\"origin\", \"destination\") \\\n",
    "    .agg(\n",
    "        avg(\"delay\").alias(\"avg_delay\"),\n",
    "        max(\"delay\").alias(\"max_delay\"),\n",
    "        count(\"*\").alias(\"num_flights\"),\n",
    "        count(when(col(\"delay_category\") == \"Very High\", 1)).alias(\"very_high_delay_count\"),\n",
    "        round(\n",
    "            100 * sum(when(col(\"delay\") > 120, 1).otherwise(0)) / count(\"*\"), 2\n",
    "        ).alias(\"pct_delay_over_120\")\n",
    "    ) \\\n",
    "    .filter(col(\"num_flights\") > 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a52633ff-4974-4471-8639-cb3248c82995",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+------------------+------------------+\n|origin|destination|         avg_delay|pct_delay_over_120|\n+------+-----------+------------------+------------------+\n|   JFK|        EGE|261.61538461538464|             84.62|\n|   JFK|        SAT|175.66666666666666|             83.33|\n|   JFK|        HOU|228.85714285714286|             71.43|\n|   EWR|        STT|             152.5|             66.67|\n|   JFK|        PIT|143.11111111111111|             66.67|\n+------+-----------+------------------+------------------+\nonly showing top 5 rows\n+------+---------------------+\n|origin|num_high_delay_routes|\n+------+---------------------+\n|   JFK|                   44|\n|   EWR|                   34|\n|   LGA|                   28|\n+------+---------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# SQL queries\n",
    "\n",
    "df_agg.createOrReplaceTempView(\"flights_summary\")\n",
    "\n",
    "sql_result1 = spark.sql(\"\"\"\n",
    "    SELECT origin, destination, avg_delay, pct_delay_over_120\n",
    "    FROM flights_summary\n",
    "    WHERE pct_delay_over_120 > 30\n",
    "    ORDER BY pct_delay_over_120 DESC\n",
    "\"\"\")\n",
    "\n",
    "sql_result2 = spark.sql(\"\"\"\n",
    "    SELECT origin, COUNT(*) AS num_high_delay_routes\n",
    "    FROM flights_summary\n",
    "    WHERE avg_delay > 120\n",
    "    GROUP BY origin\n",
    "    ORDER BY num_high_delay_routes DESC\n",
    "\"\"\")\n",
    "\n",
    "# Show results\n",
    "sql_result1.show(5)\n",
    "sql_result2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "123b208a-781a-47d5-a20f-652cefc9e328",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+------------------+---------+-----------+---------------------+------------------+\n|origin|destination|         avg_delay|max_delay|num_flights|very_high_delay_count|pct_delay_over_120|\n+------+-----------+------------------+---------+-----------+---------------------+------------------+\n|   EWR|        ORF|  94.3529411764706|      170|        170|                    0|             17.65|\n|   EWR|        FLL|120.73873873873873|      307|       1110|                  160|             41.44|\n|   EWR|        DEN|131.43548387096774|      292|        620|                  140|             45.16|\n|   EWR|        DSM|102.28571428571429|      127|         70|                    0|             28.57|\n|   EWR|        SAV|121.36363636363636|      246|        220|                   50|             40.91|\n|   EWR|        GSP|107.95454545454545|      229|        220|                   30|             27.27|\n|   EWR|        SAN|145.55555555555554|      348|        180|                   60|             55.56|\n|   EWR|        TPA|             130.4|      371|        500|                  110|              48.0|\n|   EWR|        SLC|           109.875|      211|         80|                   10|              37.5|\n|   EWR|        GSO|141.04545454545453|      370|        220|                   40|              50.0|\n+------+-----------+------------------+---------+-----------+---------------------+------------------+\nonly showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# Write results to a table\n",
    "df_agg.write.mode(\"overwrite\").saveAsTable(\"flights_summary_table\")\n",
    "\n",
    "spark.sql(\"SELECT * FROM flights_summary_table\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8299a9a6-7b67-4aa0-9933-3fba2fdbd718",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n'Filter '`>`('num_flights, 50)\n+- 'Aggregate ['origin, 'destination], ['origin, 'destination, 'avg('delay) AS avg_delay#11225, 'max('delay) AS max_delay#11226, 'count(*) AS num_flights#11227, 'count('when('`==`('delay_category, Very High), 1)) AS very_high_delay_count#11228, 'round('`/`('`*`(100, 'sum('when('`>`('delay, 120), 1, 0))), 'count(*)), 2) AS pct_delay_over_120#11229]\n   +- Project [date#11125, delay#11126, distance#11127, origin#11128, destination#11129, CASE WHEN (delay#11126 > 180) THEN Very High WHEN (delay#11126 > 120) THEN High ELSE Moderate END AS delay_category#11223]\n      +- Filter origin#11128 IN (JFK,LGA,EWR)\n         +- Filter (delay#11126 > 60)\n            +- Union false, false\n               :- Union false, false\n               :  :- Union false, false\n               :  :  :- Union false, false\n               :  :  :  :- Union false, false\n               :  :  :  :  :- Union false, false\n               :  :  :  :  :  :- Union false, false\n               :  :  :  :  :  :  :- Union false, false\n               :  :  :  :  :  :  :  :- Union false, false\n               :  :  :  :  :  :  :  :  :- Relation [date#11125,delay#11126,distance#11127,origin#11128,destination#11129] csv\n               :  :  :  :  :  :  :  :  +- Relation [date#11177,delay#11178,distance#11179,origin#11180,destination#11181] csv\n               :  :  :  :  :  :  :  +- Relation [date#11182,delay#11183,distance#11184,origin#11185,destination#11186] csv\n               :  :  :  :  :  :  +- Relation [date#11187,delay#11188,distance#11189,origin#11190,destination#11191] csv\n               :  :  :  :  :  +- Relation [date#11192,delay#11193,distance#11194,origin#11195,destination#11196] csv\n               :  :  :  :  +- Relation [date#11197,delay#11198,distance#11199,origin#11200,destination#11201] csv\n               :  :  :  +- Relation [date#11202,delay#11203,distance#11204,origin#11205,destination#11206] csv\n               :  :  +- Relation [date#11207,delay#11208,distance#11209,origin#11210,destination#11211] csv\n               :  +- Relation [date#11212,delay#11213,distance#11214,origin#11215,destination#11216] csv\n               +- Relation [date#11217,delay#11218,distance#11219,origin#11220,destination#11221] csv\n\n== Analyzed Logical Plan ==\norigin: string, destination: string, avg_delay: double, max_delay: int, num_flights: bigint, very_high_delay_count: bigint, pct_delay_over_120: double\nFilter (num_flights#11227L > cast(50 as bigint))\n+- Aggregate [origin#11128, destination#11129], [origin#11128, destination#11129, avg(delay#11126) AS avg_delay#11225, max(delay#11126) AS max_delay#11226, count(1) AS num_flights#11227L, count(CASE WHEN (delay_category#11223 = Very High) THEN 1 END) AS very_high_delay_count#11228L, round((cast((cast(100 as bigint) * sum(CASE WHEN (delay#11126 > 120) THEN 1 ELSE 0 END)) as double) / cast(count(1) as double)), 2) AS pct_delay_over_120#11229]\n   +- Project [date#11125, delay#11126, distance#11127, origin#11128, destination#11129, CASE WHEN (delay#11126 > 180) THEN Very High WHEN (delay#11126 > 120) THEN High ELSE Moderate END AS delay_category#11223]\n      +- Filter origin#11128 IN (JFK,LGA,EWR)\n         +- Filter (delay#11126 > 60)\n            +- Union false, false\n               :- Union false, false\n               :  :- Union false, false\n               :  :  :- Union false, false\n               :  :  :  :- Union false, false\n               :  :  :  :  :- Union false, false\n               :  :  :  :  :  :- Union false, false\n               :  :  :  :  :  :  :- Union false, false\n               :  :  :  :  :  :  :  :- Union false, false\n               :  :  :  :  :  :  :  :  :- Relation [date#11125,delay#11126,distance#11127,origin#11128,destination#11129] csv\n               :  :  :  :  :  :  :  :  +- Relation [date#11177,delay#11178,distance#11179,origin#11180,destination#11181] csv\n               :  :  :  :  :  :  :  +- Relation [date#11182,delay#11183,distance#11184,origin#11185,destination#11186] csv\n               :  :  :  :  :  :  +- Relation [date#11187,delay#11188,distance#11189,origin#11190,destination#11191] csv\n               :  :  :  :  :  +- Relation [date#11192,delay#11193,distance#11194,origin#11195,destination#11196] csv\n               :  :  :  :  +- Relation [date#11197,delay#11198,distance#11199,origin#11200,destination#11201] csv\n               :  :  :  +- Relation [date#11202,delay#11203,distance#11204,origin#11205,destination#11206] csv\n               :  :  +- Relation [date#11207,delay#11208,distance#11209,origin#11210,destination#11211] csv\n               :  +- Relation [date#11212,delay#11213,distance#11214,origin#11215,destination#11216] csv\n               +- Relation [date#11217,delay#11218,distance#11219,origin#11220,destination#11221] csv\n\n== Optimized Logical Plan ==\nFilter (num_flights#11227L > 50)\n+- Aggregate [origin#11128, destination#11129], [origin#11128, destination#11129, avg(delay#11126) AS avg_delay#11225, max(delay#11126) AS max_delay#11226, count(1) AS num_flights#11227L, count(CASE WHEN (delay_category#11223 = Very High) THEN 1 END) AS very_high_delay_count#11228L, round((cast((sum(CASE WHEN (delay#11126 > 120) THEN 1 ELSE 0 END) * 100) as double) / cast(count(1) as double)), 2) AS pct_delay_over_120#11229]\n   +- Union false, false\n      :- Project [delay#11126, origin#11128, destination#11129, CASE WHEN (delay#11126 > 180) THEN Very High WHEN (delay#11126 > 120) THEN High ELSE Moderate END AS delay_category#11223]\n      :  +- Filter ((isnotnull(delay#11126) AND (delay#11126 > 60)) AND origin#11128 IN (JFK,LGA,EWR))\n      :     +- Relation [date#11125,delay#11126,distance#11127,origin#11128,destination#11129] csv\n      :- Project [delay#11178, origin#11180, destination#11181, CASE WHEN (delay#11178 > 180) THEN Very High WHEN (delay#11178 > 120) THEN High ELSE Moderate END AS delay_category#11911]\n      :  +- Filter ((isnotnull(delay#11178) AND (delay#11178 > 60)) AND origin#11180 IN (JFK,LGA,EWR))\n      :     +- Relation [date#11177,delay#11178,distance#11179,origin#11180,destination#11181] csv\n      :- Project [delay#11183, origin#11185, destination#11186, CASE WHEN (delay#11183 > 180) THEN Very High WHEN (delay#11183 > 120) THEN High ELSE Moderate END AS delay_category#11912]\n      :  +- Filter ((isnotnull(delay#11183) AND (delay#11183 > 60)) AND origin#11185 IN (JFK,LGA,EWR))\n      :     +- Relation [date#11182,delay#11183,distance#11184,origin#11185,destination#11186] csv\n      :- Project [delay#11188, origin#11190, destination#11191, CASE WHEN (delay#11188 > 180) THEN Very High WHEN (delay#11188 > 120) THEN High ELSE Moderate END AS delay_category#11913]\n      :  +- Filter ((isnotnull(delay#11188) AND (delay#11188 > 60)) AND origin#11190 IN (JFK,LGA,EWR))\n      :     +- Relation [date#11187,delay#11188,distance#11189,origin#11190,destination#11191] csv\n      :- Project [delay#11193, origin#11195, destination#11196, CASE WHEN (delay#11193 > 180) THEN Very High WHEN (delay#11193 > 120) THEN High ELSE Moderate END AS delay_category#11914]\n      :  +- Filter ((isnotnull(delay#11193) AND (delay#11193 > 60)) AND origin#11195 IN (JFK,LGA,EWR))\n      :     +- Relation [date#11192,delay#11193,distance#11194,origin#11195,destination#11196] csv\n      :- Project [delay#11198, origin#11200, destination#11201, CASE WHEN (delay#11198 > 180) THEN Very High WHEN (delay#11198 > 120) THEN High ELSE Moderate END AS delay_category#11915]\n      :  +- Filter ((isnotnull(delay#11198) AND (delay#11198 > 60)) AND origin#11200 IN (JFK,LGA,EWR))\n      :     +- Relation [date#11197,delay#11198,distance#11199,origin#11200,destination#11201] csv\n      :- Project [delay#11203, origin#11205, destination#11206, CASE WHEN (delay#11203 > 180) THEN Very High WHEN (delay#11203 > 120) THEN High ELSE Moderate END AS delay_category#11916]\n      :  +- Filter ((isnotnull(delay#11203) AND (delay#11203 > 60)) AND origin#11205 IN (JFK,LGA,EWR))\n      :     +- Relation [date#11202,delay#11203,distance#11204,origin#11205,destination#11206] csv\n      :- Project [delay#11208, origin#11210, destination#11211, CASE WHEN (delay#11208 > 180) THEN Very High WHEN (delay#11208 > 120) THEN High ELSE Moderate END AS delay_category#11917]\n      :  +- Filter ((isnotnull(delay#11208) AND (delay#11208 > 60)) AND origin#11210 IN (JFK,LGA,EWR))\n      :     +- Relation [date#11207,delay#11208,distance#11209,origin#11210,destination#11211] csv\n      :- Project [delay#11213, origin#11215, destination#11216, CASE WHEN (delay#11213 > 180) THEN Very High WHEN (delay#11213 > 120) THEN High ELSE Moderate END AS delay_category#11918]\n      :  +- Filter ((isnotnull(delay#11213) AND (delay#11213 > 60)) AND origin#11215 IN (JFK,LGA,EWR))\n      :     +- Relation [date#11212,delay#11213,distance#11214,origin#11215,destination#11216] csv\n      +- Project [delay#11218, origin#11220, destination#11221, CASE WHEN (delay#11218 > 180) THEN Very High WHEN (delay#11218 > 120) THEN High ELSE Moderate END AS delay_category#11919]\n         +- Filter ((isnotnull(delay#11218) AND (delay#11218 > 60)) AND origin#11220 IN (JFK,LGA,EWR))\n            +- Relation [date#11217,delay#11218,distance#11219,origin#11220,destination#11221] csv\n\n== Physical Plan ==\nAdaptiveSparkPlan isFinalPlan=false\n+- == Initial Plan ==\n   ColumnarToRow\n   +- PhotonResultStage\n      +- PhotonFilter (num_flights#11227L > 50)\n         +- PhotonGroupingAgg(limit=None, keys=[origin#11128, destination#11129], functions=[finalmerge_avg(merge sum#11922, count#11923L) AS avg(delay)#11907, finalmerge_max(merge max#11925) AS max(delay)#11908, finalmerge_count(merge count#11927L) AS count(1)#11905L, finalmerge_count(merge count#11929L) AS count(CASE WHEN (delay_category = Very High) THEN 1 END)#11909L, finalmerge_sum(merge sum#11931L) AS sum(CASE WHEN (delay > 120) THEN 1 ELSE 0 END)#11910L], output=[origin#11128, destination#11129, avg_delay#11225, max_delay#11226, num_flights#11227L, very_high_delay_count#11228L, pct_delay_over_120#11229])\n            +- PhotonShuffleExchangeSource\n               +- PhotonShuffleMapStage ENSURE_REQUIREMENTS, [id=#9737]\n                  +- PhotonShuffleExchangeSink hashpartitioning(origin#11128, destination#11129, 1024)\n                     +- PhotonGroupingAgg(limit=None, keys=[origin#11128, destination#11129], functions=[partial_avg(delay#11126) AS (sum#11922, count#11923L), partial_max(delay#11126) AS max#11925, partial_count(1) AS count#11927L, partial_count(CASE WHEN (delay_category#11223 = Very High) THEN 1 END) AS count#11929L, partial_sum(CASE WHEN (delay#11126 > 120) THEN 1 ELSE 0 END) AS sum#11931L], output=[origin#11128, destination#11129, sum#11922, count#11923L, max#11925, count#11927L, count#11929L, sum#11931L])\n                        +- PhotonUnion Generic\n                           :- PhotonProject [delay#11126, origin#11128, destination#11129, CASE WHEN (delay#11126 > 180) THEN Very High WHEN (delay#11126 > 120) THEN High ELSE Moderate END AS delay_category#11223]\n                           :  +- PhotonFilter ((isnotnull(delay#11126) AND (delay#11126 > 60)) AND origin#11128 IN (JFK,LGA,EWR))\n                           :     +- PhotonRowToColumnar\n                           :        +- FileScan csv [delay#11126,origin#11128,destination#11129] Batched: false, DataFilters: [isnotnull(delay#11126), (delay#11126 > 60), origin#11128 IN (JFK,LGA,EWR)], Format: CSV, Location: InMemoryFileIndex(1 paths)[dbfs:/databricks-datasets/flights/departuredelays.csv], PartitionFilters: [], PushedFilters: [IsNotNull(delay), GreaterThan(delay,60), In(origin, [EWR,JFK,LGA])], ReadSchema: struct<delay:int,origin:string,destination:string>\n                           :- PhotonProject [delay#11178, origin#11180, destination#11181, CASE WHEN (delay#11178 > 180) THEN Very High WHEN (delay#11178 > 120) THEN High ELSE Moderate END AS delay_category#11911]\n                           :  +- PhotonFilter ((isnotnull(delay#11178) AND (delay#11178 > 60)) AND origin#11180 IN (JFK,LGA,EWR))\n                           :     +- PhotonRowToColumnar\n                           :        +- FileScan csv [delay#11178,origin#11180,destination#11181] Batched: false, DataFilters: [isnotnull(delay#11178), (delay#11178 > 60), origin#11180 IN (JFK,LGA,EWR)], Format: CSV, Location: InMemoryFileIndex(1 paths)[dbfs:/databricks-datasets/flights/departuredelays.csv], PartitionFilters: [], PushedFilters: [IsNotNull(delay), GreaterThan(delay,60), In(origin, [EWR,JFK,LGA])], ReadSchema: struct<delay:int,origin:string,destination:string>\n                           :- PhotonProject [delay#11183, origin#11185, destination#11186, CASE WHEN (delay#11183 > 180) THEN Very High WHEN (delay#11183 > 120) THEN High ELSE Moderate END AS delay_category#11912]\n                           :  +- PhotonFilter ((isnotnull(delay#11183) AND (delay#11183 > 60)) AND origin#11185 IN (JFK,LGA,EWR))\n                           :     +- PhotonRowToColumnar\n                           :        +- FileScan csv [delay#11183,origin#11185,destination#11186] Batched: false, DataFilters: [isnotnull(delay#11183), (delay#11183 > 60), origin#11185 IN (JFK,LGA,EWR)], Format: CSV, Location: InMemoryFileIndex(1 paths)[dbfs:/databricks-datasets/flights/departuredelays.csv], PartitionFilters: [], PushedFilters: [IsNotNull(delay), GreaterThan(delay,60), In(origin, [EWR,JFK,LGA])], ReadSchema: struct<delay:int,origin:string,destination:string>\n                           :- PhotonProject [delay#11188, origin#11190, destination#11191, CASE WHEN (delay#11188 > 180) THEN Very High WHEN (delay#11188 > 120) THEN High ELSE Moderate END AS delay_category#11913]\n                           :  +- PhotonFilter ((isnotnull(delay#11188) AND (delay#11188 > 60)) AND origin#11190 IN (JFK,LGA,EWR))\n                           :     +- PhotonRowToColumnar\n                           :        +- FileScan csv [delay#11188,origin#11190,destination#11191] Batched: false, DataFilters: [isnotnull(delay#11188), (delay#11188 > 60), origin#11190 IN (JFK,LGA,EWR)], Format: CSV, Location: InMemoryFileIndex(1 paths)[dbfs:/databricks-datasets/flights/departuredelays.csv], PartitionFilters: [], PushedFilters: [IsNotNull(delay), GreaterThan(delay,60), In(origin, [EWR,JFK,LGA])], ReadSchema: struct<delay:int,origin:string,destination:string>\n                           :- PhotonProject [delay#11193, origin#11195, destination#11196, CASE WHEN (delay#11193 > 180) THEN Very High WHEN (delay#11193 > 120) THEN High ELSE Moderate END AS delay_category#11914]\n                           :  +- PhotonFilter ((isnotnull(delay#11193) AND (delay#11193 > 60)) AND origin#11195 IN (JFK,LGA,EWR))\n                           :     +- PhotonRowToColumnar\n                           :        +- FileScan csv [delay#11193,origin#11195,destination#11196] Batched: false, DataFilters: [isnotnull(delay#11193), (delay#11193 > 60), origin#11195 IN (JFK,LGA,EWR)], Format: CSV, Location: InMemoryFileIndex(1 paths)[dbfs:/databricks-datasets/flights/departuredelays.csv], PartitionFilters: [], PushedFilters: [IsNotNull(delay), GreaterThan(delay,60), In(origin, [EWR,JFK,LGA])], ReadSchema: struct<delay:int,origin:string,destination:string>\n                           :- PhotonProject [delay#11198, origin#11200, destination#11201, CASE WHEN (delay#11198 > 180) THEN Very High WHEN (delay#11198 > 120) THEN High ELSE Moderate END AS delay_category#11915]\n                           :  +- PhotonFilter ((isnotnull(delay#11198) AND (delay#11198 > 60)) AND origin#11200 IN (JFK,LGA,EWR))\n                           :     +- PhotonRowToColumnar\n                           :        +- FileScan csv [delay#11198,origin#11200,destination#11201] Batched: false, DataFilters: [isnotnull(delay#11198), (delay#11198 > 60), origin#11200 IN (JFK,LGA,EWR)], Format: CSV, Location: InMemoryFileIndex(1 paths)[dbfs:/databricks-datasets/flights/departuredelays.csv], PartitionFilters: [], PushedFilters: [IsNotNull(delay), GreaterThan(delay,60), In(origin, [EWR,JFK,LGA])], ReadSchema: struct<delay:int,origin:string,destination:string>\n                           :- PhotonProject [delay#11203, origin#11205, destination#11206, CASE WHEN (delay#11203 > 180) THEN Very High WHEN (delay#11203 > 120) THEN High ELSE Moderate END AS delay_category#11916]\n                           :  +- PhotonFilter ((isnotnull(delay#11203) AND (delay#11203 > 60)) AND origin#11205 IN (JFK,LGA,EWR))\n                           :     +- PhotonRowToColumnar\n                           :        +- FileScan csv [delay#11203,origin#11205,destination#11206] Batched: false, DataFilters: [isnotnull(delay#11203), (delay#11203 > 60), origin#11205 IN (JFK,LGA,EWR)], Format: CSV, Location: InMemoryFileIndex(1 paths)[dbfs:/databricks-datasets/flights/departuredelays.csv], PartitionFilters: [], PushedFilters: [IsNotNull(delay), GreaterThan(delay,60), In(origin, [EWR,JFK,LGA])], ReadSchema: struct<delay:int,origin:string,destination:string>\n                           :- PhotonProject [delay#11208, origin#11210, destination#11211, CASE WHEN (delay#11208 > 180) THEN Very High WHEN (delay#11208 > 120) THEN High ELSE Moderate END AS delay_category#11917]\n                           :  +- PhotonFilter ((isnotnull(delay#11208) AND (delay#11208 > 60)) AND origin#11210 IN (JFK,LGA,EWR))\n                           :     +- PhotonRowToColumnar\n                           :        +- FileScan csv [delay#11208,origin#11210,destination#11211] Batched: false, DataFilters: [isnotnull(delay#11208), (delay#11208 > 60), origin#11210 IN (JFK,LGA,EWR)], Format: CSV, Location: InMemoryFileIndex(1 paths)[dbfs:/databricks-datasets/flights/departuredelays.csv], PartitionFilters: [], PushedFilters: [IsNotNull(delay), GreaterThan(delay,60), In(origin, [EWR,JFK,LGA])], ReadSchema: struct<delay:int,origin:string,destination:string>\n                           :- PhotonProject [delay#11213, origin#11215, destination#11216, CASE WHEN (delay#11213 > 180) THEN Very High WHEN (delay#11213 > 120) THEN High ELSE Moderate END AS delay_category#11918]\n                           :  +- PhotonFilter ((isnotnull(delay#11213) AND (delay#11213 > 60)) AND origin#11215 IN (JFK,LGA,EWR))\n                           :     +- PhotonRowToColumnar\n                           :        +- FileScan csv [delay#11213,origin#11215,destination#11216] Batched: false, DataFilters: [isnotnull(delay#11213), (delay#11213 > 60), origin#11215 IN (JFK,LGA,EWR)], Format: CSV, Location: InMemoryFileIndex(1 paths)[dbfs:/databricks-datasets/flights/departuredelays.csv], PartitionFilters: [], PushedFilters: [IsNotNull(delay), GreaterThan(delay,60), In(origin, [EWR,JFK,LGA])], ReadSchema: struct<delay:int,origin:string,destination:string>\n                           +- PhotonProject [delay#11218, origin#11220, destination#11221, CASE WHEN (delay#11218 > 180) THEN Very High WHEN (delay#11218 > 120) THEN High ELSE Moderate END AS delay_category#11919]\n                              +- PhotonFilter ((isnotnull(delay#11218) AND (delay#11218 > 60)) AND origin#11220 IN (JFK,LGA,EWR))\n                                 +- PhotonRowToColumnar\n                                    +- FileScan csv [delay#11218,origin#11220,destination#11221] Batched: false, DataFilters: [isnotnull(delay#11218), (delay#11218 > 60), origin#11220 IN (JFK,LGA,EWR)], Format: CSV, Location: InMemoryFileIndex(1 paths)[dbfs:/databricks-datasets/flights/departuredelays.csv], PartitionFilters: [], PushedFilters: [IsNotNull(delay), GreaterThan(delay,60), In(origin, [EWR,JFK,LGA])], ReadSchema: struct<delay:int,origin:string,destination:string>\n\n== Photon Explanation ==\nThe query is fully supported by Photon.\n"
     ]
    }
   ],
   "source": [
    "# 2. Performance Analysis\n",
    "df_agg.explain(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71d9cd15-0de7-4a3c-b53b-5a9e270a78a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+--------+------+-----------+\n|   date|delay|distance|origin|destination|\n+-------+-----+--------+------+-----------+\n|1011245|    6|     602|   ABE|        ATL|\n|1020600|   -8|     369|   ABE|        DTW|\n|1021245|   -2|     602|   ABE|        ATL|\n|1020605|   -4|     602|   ABE|        ATL|\n|1031245|   -4|     602|   ABE|        ATL|\n|1030605|    0|     602|   ABE|        ATL|\n|1041243|   10|     602|   ABE|        ATL|\n|1040605|   28|     602|   ABE|        ATL|\n|1051245|   88|     602|   ABE|        ATL|\n|1050605|    9|     602|   ABE|        ATL|\n|1061215|   -6|     602|   ABE|        ATL|\n|1061725|   69|     602|   ABE|        ATL|\n|1061230|    0|     369|   ABE|        DTW|\n|1060625|   -3|     602|   ABE|        ATL|\n|1070600|    0|     369|   ABE|        DTW|\n|1071725|    0|     602|   ABE|        ATL|\n|1071230|    0|     369|   ABE|        DTW|\n|1070625|    0|     602|   ABE|        ATL|\n|1071219|    0|     569|   ABE|        ORD|\n|1080600|    0|     369|   ABE|        DTW|\n+-------+-----+--------+------+-----------+\nonly showing top 20 rows\nTransformation Time: 0.0003 seconds\nRecord Count: 13915780\nAction (Show) Time: 0.5391 seconds\n"
     ]
    }
   ],
   "source": [
    "# 3. Actions vs. Transformations\n",
    "# Transformation: Select specific columns (lazy)\n",
    "start_transformation_time = time.time()\n",
    "transformation = df_large.select(\"date\", \"delay\", \"distance\", \"origin\", \"destination\")\n",
    "end_transformation_time = time.time()\n",
    "transformation_time = end_transformation_time - start_transformation_time\n",
    "\n",
    "# Action: Count the number of records (eager)\n",
    "start_action_count_time = time.time()\n",
    "record_count = transformation.count()\n",
    "end_action_count_time = time.time()\n",
    "action_count_time = end_action_count_time - start_action_count_time\n",
    "\n",
    "# Action: Show the first few rows (eager)\n",
    "start_action_show_time = time.time()\n",
    "sample_data = transformation.show()\n",
    "end_action_show_time = time.time()\n",
    "action_show_time = end_action_show_time - start_action_show_time\n",
    "\n",
    "# Display results\n",
    "print(f\"Transformation Time: {transformation_time:.4f} seconds\")\n",
    "print(f\"Record Count: {record_count}\")\n",
    "print(f\"Action (Show) Time: {action_show_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b2cade0-2112-4ac4-aa98-2d830a918db6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+----------+\n|delay|Delayed|prediction|\n+-----+-------+----------+\n|   -8|      0|       0.0|\n|   -4|      0|       0.0|\n|   -7|      0|       0.0|\n|    0|      0|       0.0|\n|    5|      1|       0.0|\n|    0|      0|       0.0|\n|   -6|      0|       0.0|\n|   -3|      0|       0.0|\n|    0|      0|       0.0|\n|   -9|      0|       0.0|\n+-----+-------+----------+\nonly showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# 4. Machine Learning\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# Create a new column 'Delayed' (1 if delay > 0, 0 otherwise)\n",
    "df_large = df_large.withColumn(\"Delayed\", when(col(\"delay\") > 0, 1).otherwise(0))\n",
    "\n",
    "# Index categorical features and one-hot encode the indexed features\n",
    "origin_indexer = StringIndexer(inputCol=\"origin\", outputCol=\"origin_index\")\n",
    "destination_indexer = StringIndexer(inputCol=\"destination\", outputCol=\"destination_index\")\n",
    "origin_encoder = OneHotEncoder(inputCols=[\"origin_index\"], outputCols=[\"origin_vec\"])\n",
    "destination_encoder = OneHotEncoder(inputCols=[\"destination_index\"], outputCols=[\"destination_vec\"])\n",
    "\n",
    "features = [\"distance\", \"origin_vec\"]  \n",
    "vector_assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
    "\n",
    "random_forest = RandomForestClassifier(numTrees=5, maxDepth=5, featuresCol=\"features\", labelCol=\"Delayed\")\n",
    "\n",
    "pipeline = Pipeline(stages=[origin_indexer, destination_indexer, origin_encoder, destination_encoder, vector_assembler, random_forest])\n",
    "train_data, test_data = df_large.randomSplit([0.8, 0.2], seed=42)\n",
    "model = pipeline.fit(train_data)\n",
    "\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Show some predictions\n",
    "predictions.select(\"delay\", \"Delayed\", \"prediction\").show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27e8f728-556a-48f1-ac3c-0436df5b7701",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Week 11 Data Processing",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}